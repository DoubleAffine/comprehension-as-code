---
phase: 04-convergence-detection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/comprehension/convergence/__init__.py
  - src/comprehension/convergence/embedder.py
  - src/comprehension/convergence/vector_store.py
  - tests/test_embedder.py
  - tests/test_vector_store.py
autonomous: true

must_haves:
  truths:
    - "Comprehension belief statements can be converted to 384-dimensional embeddings"
    - "Embeddings can be stored and retrieved from SQLite via sqlite-vec"
    - "KNN queries return comprehension IDs ranked by cosine similarity"
  artifacts:
    - path: "src/comprehension/convergence/embedder.py"
      provides: "ComprehensionEmbedder class wrapping SentenceTransformer"
      exports: ["ComprehensionEmbedder"]
    - path: "src/comprehension/convergence/vector_store.py"
      provides: "VectorStore for sqlite-vec operations"
      exports: ["VectorStore"]
    - path: "src/comprehension/convergence/__init__.py"
      provides: "Module exports"
      exports: ["ComprehensionEmbedder", "VectorStore"]
  key_links:
    - from: "src/comprehension/convergence/embedder.py"
      to: "sentence_transformers.SentenceTransformer"
      via: "model initialization"
      pattern: "SentenceTransformer.*all-MiniLM-L6-v2"
    - from: "src/comprehension/convergence/vector_store.py"
      to: "sqlite_vec"
      via: "extension loading"
      pattern: "sqlite_vec\\.load"
---

<objective>
Create the foundation for convergence detection: semantic embeddings and vector storage.

Purpose: Comprehension similarity requires comparing semantic structure, not keywords. This plan establishes the embedding pipeline (converting belief statements to vectors) and the vector store (sqlite-vec for efficient KNN queries).

Output: ComprehensionEmbedder and VectorStore classes ready for similarity queries in Plan 02.
</objective>

<execution_context>
@/Users/ianphilipp/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ianphilipp/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-convergence-detection/04-RESEARCH.md

# Existing code patterns
@src/comprehension/schema/comprehension.py
@src/comprehension/store/repository.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ComprehensionEmbedder</name>
  <files>
    src/comprehension/convergence/__init__.py
    src/comprehension/convergence/embedder.py
    tests/test_embedder.py
  </files>
  <action>
Create convergence module with embedder:

1. Create `src/comprehension/convergence/__init__.py`:
   - Empty for now, will add exports after classes exist

2. Create `src/comprehension/convergence/embedder.py`:
   - Class `ComprehensionEmbedder` with:
     - `__init__(self, model_name: str = "all-MiniLM-L6-v2")` - Initialize SentenceTransformer model
     - `embed(self, comprehension: Comprehension) -> np.ndarray` - Embed a comprehension
       - Combine prior.statement and posterior.statement: `f"{comp.prior.statement} {comp.posterior.statement}"`
       - Use `self._model.encode(text, normalize_embeddings=True)` for normalized vectors
       - Return np.ndarray of shape (384,)
     - `embed_text(self, text: str) -> np.ndarray` - Lower-level method for testing
   - Type hints throughout, docstrings for public methods
   - Model loaded once in __init__, reused for all embeds

3. Create `tests/test_embedder.py`:
   - Test embedding returns correct shape (384,)
   - Test normalized embeddings (L2 norm ~= 1.0)
   - Test similar texts have higher similarity than dissimilar texts
   - Use real model (all-MiniLM-L6-v2) - no mocking for semantic tests

Import pattern: `from sentence_transformers import SentenceTransformer`

Do NOT use lazy loading - model should be loaded in __init__ per research guidance on avoiding repeated load overhead.
  </action>
  <verify>
pytest tests/test_embedder.py -v
# All tests pass
# Model loads successfully (may take 1-3 seconds first time)
  </verify>
  <done>
ComprehensionEmbedder creates 384-dim normalized embeddings from comprehension belief statements. Tests verify shape, normalization, and semantic similarity properties.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create VectorStore with sqlite-vec</name>
  <files>
    src/comprehension/convergence/vector_store.py
    src/comprehension/convergence/__init__.py
    tests/test_vector_store.py
  </files>
  <action>
Create VectorStore for sqlite-vec operations:

1. Create `src/comprehension/convergence/vector_store.py`:
   - Class `VectorStore` with:
     - `__init__(self, db_path: Union[str, Path])` - Store path, call _ensure_schema()
     - `_connect(self) -> sqlite3.Connection` - Create connection, load sqlite_vec extension
     - `_ensure_schema(self) -> None` - Create virtual table and mapping table:
       ```sql
       CREATE VIRTUAL TABLE IF NOT EXISTS comprehension_vectors
       USING vec0(embedding float[384])

       CREATE TABLE IF NOT EXISTS vector_id_map (
         rowid INTEGER PRIMARY KEY,
         comprehension_id TEXT UNIQUE NOT NULL
       )
       ```
     - `_serialize(self, vector: np.ndarray) -> bytes` - Convert np.ndarray to sqlite-vec format using struct.pack
     - `add(self, comprehension_id: str, embedding: np.ndarray) -> None` - Insert or replace vector
       - Use stable rowid: `hash(comprehension_id) & 0x7FFFFFFF` (positive int32)
       - Insert into both comprehension_vectors and vector_id_map
     - `remove(self, comprehension_id: str) -> bool` - Delete vector by comprehension ID
     - `query_knn(self, embedding: np.ndarray, limit: int = 5) -> List[Tuple[str, float]]` - KNN query
       - Returns list of (comprehension_id, distance) tuples
       - Uses `WHERE embedding MATCH ? ORDER BY distance LIMIT ?`
     - `count(self) -> int` - Number of vectors stored

   - Connection-per-operation pattern (like existing repository.py)
   - Extension loading: `conn.enable_load_extension(True)`, `sqlite_vec.load(conn)`, `conn.enable_load_extension(False)`

2. Update `src/comprehension/convergence/__init__.py`:
   - Export: ComprehensionEmbedder, VectorStore

3. Create `tests/test_vector_store.py`:
   - Test add/remove operations
   - Test KNN query returns correct order (closest first)
   - Test count
   - Test upsert (add same ID twice)
   - Use temp database (pytest tmp_path fixture)

Import pattern:
```python
import sqlite3
import sqlite_vec
import struct
import numpy as np
```
  </action>
  <verify>
pytest tests/test_vector_store.py -v
# All tests pass
# sqlite-vec extension loads correctly
  </verify>
  <done>
VectorStore stores and queries 384-dim embeddings via sqlite-vec. KNN queries return comprehension IDs ranked by cosine distance. Tests verify CRUD and query operations.
  </done>
</task>

</tasks>

<verification>
After both tasks:

```bash
# All convergence tests pass
pytest tests/test_embedder.py tests/test_vector_store.py -v

# Module imports work
python -c "from comprehension.convergence import ComprehensionEmbedder, VectorStore; print('OK')"

# Files exist
ls -la src/comprehension/convergence/
```
</verification>

<success_criteria>
- [ ] ComprehensionEmbedder embeds comprehensions to 384-dim normalized vectors
- [ ] VectorStore creates sqlite-vec virtual table and stores/queries vectors
- [ ] KNN queries return comprehension IDs in distance order
- [ ] All tests pass
- [ ] Module exports ComprehensionEmbedder and VectorStore
</success_criteria>

<output>
After completion, create `.planning/phases/04-convergence-detection/04-01-SUMMARY.md`
</output>
