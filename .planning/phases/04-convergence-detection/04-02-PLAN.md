---
phase: 04-convergence-detection
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/comprehension/convergence/similarity.py
  - src/comprehension/convergence/accumulator.py
  - src/comprehension/convergence/__init__.py
  - tests/test_similarity.py
  - tests/test_accumulator.py
autonomous: true

must_haves:
  truths:
    - "New comprehension can query 'what does this remind me of?' and get cross-domain matches"
    - "Similarity results exclude same-domain comprehensions"
    - "System tracks similarity edges between comprehensions for density analysis"
    - "Accumulation hotspots can be identified (comprehensions with connections across multiple domains)"
  artifacts:
    - path: "src/comprehension/convergence/similarity.py"
      provides: "SimilarityFinder with reminds_me_of() operation"
      exports: ["SimilarityFinder", "SimilarityMatch"]
    - path: "src/comprehension/convergence/accumulator.py"
      provides: "AccumulationTracker for density tracking"
      exports: ["AccumulationTracker", "AccumulationHotspot"]
    - path: "src/comprehension/convergence/__init__.py"
      provides: "Updated module exports"
      exports: ["ComprehensionEmbedder", "VectorStore", "SimilarityFinder", "SimilarityMatch", "AccumulationTracker", "AccumulationHotspot"]
  key_links:
    - from: "src/comprehension/convergence/similarity.py"
      to: "src/comprehension/convergence/embedder.py"
      via: "embedding query comprehension"
      pattern: "self\\._embedder\\.embed"
    - from: "src/comprehension/convergence/similarity.py"
      to: "src/comprehension/convergence/vector_store.py"
      via: "KNN query for similar vectors"
      pattern: "self\\._vector_store\\.query_knn"
    - from: "src/comprehension/convergence/similarity.py"
      to: "src/comprehension/store/repository.py"
      via: "loading comprehension by ID for domain filtering"
      pattern: "self\\._repository\\.get"
    - from: "src/comprehension/convergence/accumulator.py"
      to: "similarity_edges table"
      via: "recording similarity relationships"
      pattern: "INSERT.*similarity_edges"
---

<objective>
Implement the "reminds me of" operation and accumulation tracking for rising tide detection.

Purpose: This is the core convergence detection capability. When a new comprehension is created, it can query "what does this remind me of?" to find structurally similar comprehensions from OTHER domains. The accumulator tracks these relationships to identify where pattern density is building (rising tide).

Output: SimilarityFinder and AccumulationTracker classes completing Phase 4 requirements.
</objective>

<execution_context>
@/Users/ianphilipp/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ianphilipp/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-convergence-detection/04-RESEARCH.md
@.planning/phases/04-convergence-detection/04-01-SUMMARY.md

# Existing code
@src/comprehension/convergence/embedder.py
@src/comprehension/convergence/vector_store.py
@src/comprehension/store/repository.py
@src/comprehension/schema/comprehension.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SimilarityFinder with reminds_me_of()</name>
  <files>
    src/comprehension/convergence/similarity.py
    tests/test_similarity.py
  </files>
  <action>
Create the "reminds me of" operation:

1. Create `src/comprehension/convergence/similarity.py`:

   - Dataclass `SimilarityMatch`:
     ```python
     @dataclass
     class SimilarityMatch:
         comprehension_id: str
         domain: str
         similarity: float  # 0-1, higher is more similar
     ```

   - Class `SimilarityFinder`:
     - `__init__(self, db_path: Union[str, Path], embedder: Optional[ComprehensionEmbedder] = None)`:
       - Store db_path
       - Create or use provided embedder (default: create new ComprehensionEmbedder())
       - Create VectorStore instance
       - Create SQLiteComprehensionRepository instance (for loading comprehensions by ID)

     - `index(self, comprehension: Comprehension) -> None`:
       - Embed the comprehension
       - Add to vector store with comprehension.id

     - `remove_index(self, comprehension_id: str) -> bool`:
       - Remove from vector store

     - `reminds_me_of(self, comprehension: Comprehension, limit: int = 5, min_similarity: float = 0.75) -> List[SimilarityMatch]`:
       - Embed the query comprehension
       - Query vector store for top (limit * 3) candidates (over-fetch to allow for filtering)
       - For each result:
         - Load comprehension from repository to get domain
         - Skip if domain == query comprehension's domain (cross-domain only!)
         - Convert distance to similarity: similarity = 1 - distance
         - Skip if similarity < min_similarity
       - Return top `limit` matches as SimilarityMatch objects
       - If comprehension not indexed yet, results won't include itself

     - `find_similar_to_id(self, comprehension_id: str, limit: int = 5, min_similarity: float = 0.75) -> List[SimilarityMatch]`:
       - Load comprehension by ID from repository
       - Call reminds_me_of with loaded comprehension

2. Create `tests/test_similarity.py`:
   - Test reminds_me_of returns empty list when no comprehensions indexed
   - Test reminds_me_of excludes same-domain matches
   - Test reminds_me_of returns matches in similarity order (highest first)
   - Test min_similarity threshold filters low-similarity results
   - Test index and remove_index work correctly
   - Use factory functions to create test comprehensions with different domains/beliefs

Key insight from research: Domain exclusion is CRITICAL. The whole point of convergence detection is finding the same STRUCTURE in DIFFERENT domains. Same-domain matches are noise.

Default min_similarity of 0.75 per research recommendation.
  </action>
  <verify>
pytest tests/test_similarity.py -v
# All tests pass
# Cross-domain filtering works
  </verify>
  <done>
SimilarityFinder provides reminds_me_of() operation returning structurally similar comprehensions from OTHER domains. Domain exclusion enforced. Similarity threshold configurable.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AccumulationTracker for rising tide</name>
  <files>
    src/comprehension/convergence/accumulator.py
    src/comprehension/convergence/__init__.py
    tests/test_accumulator.py
  </files>
  <action>
Create accumulation tracking for rising tide detection:

1. Create `src/comprehension/convergence/accumulator.py`:

   - Dataclass `AccumulationHotspot`:
     ```python
     @dataclass
     class AccumulationHotspot:
         comprehension_id: str
         domain_count: int        # How many different domains have similar comprehensions
         connection_count: int    # Total number of similarity edges pointing to this
         avg_similarity: float    # Average similarity of connections
     ```

   - Class `AccumulationTracker`:
     - `__init__(self, db_path: Union[str, Path])`:
       - Store db_path
       - Call _ensure_schema()

     - `_connect(self) -> sqlite3.Connection`:
       - Standard connection (no sqlite-vec needed here)

     - `_ensure_schema(self) -> None`:
       - Create similarity_edges table:
         ```sql
         CREATE TABLE IF NOT EXISTS similarity_edges (
             source_id TEXT NOT NULL,
             target_id TEXT NOT NULL,
             similarity REAL NOT NULL,
             source_domain TEXT NOT NULL,
             target_domain TEXT NOT NULL,
             created TEXT NOT NULL,
             PRIMARY KEY (source_id, target_id)
         )
         CREATE INDEX IF NOT EXISTS idx_similarity_target
         ON similarity_edges(target_id, similarity)
         ```

     - `record_similarity(self, source_id: str, target_id: str, similarity: float, source_domain: str, target_domain: str) -> None`:
       - Insert or replace edge (upsert)
       - Store created timestamp as ISO format

     - `record_matches(self, source: Comprehension, matches: List[SimilarityMatch]) -> None`:
       - Convenience method: record all matches from a reminds_me_of query
       - For each match: record_similarity(source.id, match.comprehension_id, match.similarity, source.domain, match.domain)

     - `get_connections(self, comprehension_id: str) -> List[Tuple[str, str, float]]`:
       - Get all edges where this comprehension is source OR target
       - Returns list of (other_id, other_domain, similarity) tuples

     - `get_hotspots(self, min_domains: int = 2, min_connections: int = 3) -> List[AccumulationHotspot]`:
       - Query for comprehensions with connections across multiple domains:
         ```sql
         SELECT target_id, COUNT(DISTINCT source_domain), COUNT(*), AVG(similarity)
         FROM similarity_edges
         GROUP BY target_id
         HAVING COUNT(DISTINCT source_domain) >= ? AND COUNT(*) >= ?
         ORDER BY COUNT(DISTINCT source_domain) DESC, AVG(similarity) DESC
         ```
       - Return as AccumulationHotspot objects
       - These are CANDIDATES for meta-comprehension (Phase 5) - not created here

     - `remove_edges(self, comprehension_id: str) -> int`:
       - Remove all edges where comprehension is source or target
       - Returns count of edges removed

2. Update `src/comprehension/convergence/__init__.py`:
   - Export all classes: ComprehensionEmbedder, VectorStore, SimilarityFinder, SimilarityMatch, AccumulationTracker, AccumulationHotspot

3. Create `tests/test_accumulator.py`:
   - Test record_similarity creates edges
   - Test record_matches batch operation
   - Test get_connections returns bidirectional edges
   - Test get_hotspots identifies comprehensions with cross-domain density
   - Test remove_edges cleans up properly
   - Use temp database

Key insight: We DO NOT create meta-comprehensions here. We only TRACK where density is building. Phase 5 handles crystallization when confidence is high enough.
  </action>
  <verify>
pytest tests/test_accumulator.py -v
# All tests pass
# Hotspot detection works with domain counting
  </verify>
  <done>
AccumulationTracker records similarity relationships and identifies hotspots where structural similarity is accumulating across domains. Ready for Phase 5 crystallization logic.
  </done>
</task>

</tasks>

<verification>
After both tasks:

```bash
# All Phase 4 tests pass
pytest tests/test_embedder.py tests/test_vector_store.py tests/test_similarity.py tests/test_accumulator.py -v

# Module exports work
python -c "from comprehension.convergence import SimilarityFinder, SimilarityMatch, AccumulationTracker, AccumulationHotspot; print('OK')"

# Integration check: end-to-end flow
python -c "
from comprehension.convergence import SimilarityFinder, AccumulationTracker
from comprehension.schema import Comprehension, BeliefPrior, BeliefPosterior, ConfidenceLevel
from datetime import datetime
import tempfile
import os

# Create temp db
with tempfile.TemporaryDirectory() as tmpdir:
    db = os.path.join(tmpdir, 'test.db')
    finder = SimilarityFinder(db)
    tracker = AccumulationTracker(db)

    # Create test comprehension
    comp = Comprehension(
        id='test-1',
        topic='test',
        domain='test-domain',
        prior=BeliefPrior(statement='prior', confidence=ConfidenceLevel.MEDIUM, source='test'),
        observations=[],
        posterior=BeliefPosterior(statement='posterior', confidence=ConfidenceLevel.MEDIUM, update_reasoning='test', observations_used=[]),
        created=datetime.now(),
        updated=datetime.now()
    )

    # Index and query
    finder.index(comp)
    matches = finder.reminds_me_of(comp)
    print(f'Matches: {len(matches)} (expected 0 - no other comprehensions)')
    print('Integration OK')
"
```
</verification>

<success_criteria>
- [ ] reminds_me_of() returns structurally similar comprehensions from OTHER domains
- [ ] Same-domain matches are excluded from results
- [ ] Similarity threshold is configurable (default 0.75)
- [ ] AccumulationTracker records similarity edges
- [ ] get_hotspots() identifies comprehensions with cross-domain density
- [ ] All tests pass
- [ ] Module exports all public classes
</success_criteria>

<output>
After completion, create `.planning/phases/04-convergence-detection/04-02-SUMMARY.md`
</output>
